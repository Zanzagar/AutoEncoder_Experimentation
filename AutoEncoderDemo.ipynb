{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8274465e",
   "metadata": {},
   "source": [
    "# AutoEncoder Library Demonstration with Geological Datasets\n",
    "\n",
    "This notebook demonstrates how to use the `autoencoder_lib` package for experimenting with different autoencoder architectures, focusing on geological layered datasets for investigating latent space representation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de174e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f289db8",
   "metadata": {},
   "source": [
    "## 1. Import Components from autoencoder_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cea8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import key components from our package\n",
    "from autoencoder_lib.models import (\n",
    "    SimpleLinearAutoencoder,\n",
    "    DeeperLinearAutoencoder,\n",
    "    ConvAutoencoder,\n",
    "    DeeperConvAutoencoder,\n",
    "    VariationalAutoencoder,\n",
    "    DenoisingAutoencoder\n",
    ")\n",
    "\n",
    "from autoencoder_lib.data import (\n",
    "    ShapeDataset,\n",
    "    load_or_create_data_split\n",
    ")\n",
    "\n",
    "from autoencoder_lib.experiment import (\n",
    "    AutoEncoderWrapper,\n",
    "    ExperimentManager,\n",
    "    MultiArchitectureManager\n",
    ")\n",
    "\n",
    "from autoencoder_lib.visualization import (\n",
    "    visualize_reconstructions,\n",
    "    compare_reconstructions,\n",
    "    plot_with_labels,\n",
    "    plot_training_loss_curves,\n",
    "    enhanced_training_visualizations\n",
    ")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb7e7b",
   "metadata": {},
   "source": [
    "## 2. Loading the Geologic Layer Datasets\n",
    "\n",
    "Let's load the geological layer datasets that come with the project. We have two sets:\n",
    "1. Consistent layers: Geologic patterns with consistent layer thickness\n",
    "2. Variable layers: Geologic patterns with variable layer thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a435cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ImageFolderDataset\n",
    "from autoencoder_lib.data.datasets import ImageFolderDataset\n",
    "\n",
    "# Load the geological layer datasets\n",
    "consistent_layers_dataset = ImageFolderDataset(\n",
    "    root_dir='layered_geologic_patterns_dataset/consistent_layers',\n",
    "    img_size=64,\n",
    "    grayscale=True\n",
    ")\n",
    "\n",
    "variable_layers_dataset = ImageFolderDataset(\n",
    "    root_dir='layered_geologic_patterns_dataset/variable_layers',\n",
    "    img_size=64,\n",
    "    grayscale=True\n",
    ")\n",
    "\n",
    "# Combine datasets for some examples\n",
    "from torch.utils.data import ConcatDataset\n",
    "geo_combined_dataset = ConcatDataset([consistent_layers_dataset, variable_layers_dataset])\n",
    "\n",
    "print(f\"Consistent layers dataset: {len(consistent_layers_dataset)} images\")\n",
    "print(f\"Variable layers dataset: {len(variable_layers_dataset)} images\")\n",
    "print(f\"Combined dataset: {len(geo_combined_dataset)} images\")\n",
    "\n",
    "# Split datasets for training/validation/testing\n",
    "from autoencoder_lib.data import load_or_create_data_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split consistent layers dataset\n",
    "consistent_train, consistent_val, consistent_test = load_or_create_data_split(\n",
    "    consistent_layers_dataset,\n",
    "    test_ratio=0.2,\n",
    "    val_ratio=0.1,\n",
    "    split_file_path='consistent_layers_split.json',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Split variable layers dataset\n",
    "variable_train, variable_val, variable_test = load_or_create_data_split(\n",
    "    variable_layers_dataset,\n",
    "    test_ratio=0.2,\n",
    "    val_ratio=0.1,\n",
    "    split_file_path='variable_layers_split.json',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create data loaders for the consistent layers dataset (which we'll use primarily)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(consistent_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(consistent_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(consistent_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639be70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from our datasets\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(5):\n",
    "    # Consistent layers\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    img, _ = consistent_layers_dataset[i]\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Consistent {i+1}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Variable layers\n",
    "    plt.subplot(2, 5, i+6)\n",
    "    img, _ = variable_layers_dataset[i]\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Variable {i+1}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff5e930",
   "metadata": {},
   "source": [
    "## 3. Training a Simple Linear Autoencoder\n",
    "\n",
    "Let's train a simple linear autoencoder on our shape dataset using the `AutoEncoderWrapper` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e41819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input shape from dataset\n",
    "input_shape = consistent_layers_dataset[0][0].shape\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "\n",
    "# Create an AutoEncoderWrapper for a simple linear autoencoder\n",
    "linear_ae_wrapper = AutoEncoderWrapper(\n",
    "    model_class=SimpleLinearAutoencoder,\n",
    "    model_name=\"GeoLinearAE\",\n",
    "    input_shape=input_shape,\n",
    "    latent_dim=10,  # Using 10 dimensions in the latent space\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    results_dir='results/geo_linear_ae'\n",
    ")\n",
    "\n",
    "# Setup data loaders\n",
    "linear_ae_wrapper.train_loader = train_loader\n",
    "linear_ae_wrapper.val_loader = val_loader\n",
    "linear_ae_wrapper.test_loader = test_loader\n",
    "linear_ae_wrapper.dataloader_setup = True\n",
    "\n",
    "# Initialize the model\n",
    "linear_ae_wrapper.setup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model, metrics = linear_ae_wrapper.train(\n",
    "    epochs=20,                   # Train for 20 epochs\n",
    "    learning_rate=0.001,         # Learning rate for the optimizer\n",
    "    early_stopping_patience=5,   # Stop if no improvement for 5 epochs\n",
    "    verbose=True,                # Print training progress\n",
    "    visualize_training=True      # Create visualizations of training metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set and visualize reconstructions\n",
    "test_loss, test_metrics = linear_ae_wrapper.evaluate(\n",
    "    data_loader=test_loader,\n",
    "    visualize=True,\n",
    "    num_samples=10\n",
    ")\n",
    "\n",
    "# Visualize latent space\n",
    "linear_ae_wrapper.visualize_latent_space(\n",
    "    data_loader=test_loader,\n",
    "    method='tsne',\n",
    "    max_samples=200,\n",
    "    title=\"Geological Layers - Linear Autoencoder Latent Space\",\n",
    "    class_names=['Consistent Layers']  # Only one class for geological layers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b89d6",
   "metadata": {},
   "source": [
    "## 4. Using the ExperimentManager for Multiple Experiments\n",
    "\n",
    "The `ExperimentManager` class helps manage multiple experiments with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202633b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ExperimentManager for exploring latent dimensions\n",
    "exp_manager = ExperimentManager(\n",
    "    model_class=SimpleLinearAutoencoder,\n",
    "    results_dir='results/geo_latent_dim_exploration'\n",
    ")\n",
    "\n",
    "# Run experiments with different latent dimensions\n",
    "latent_dims = [2, 5, 10, 20]\n",
    "results_df = exp_manager.run_latent_dim_experiment(\n",
    "    dataset=consistent_layers_dataset,\n",
    "    dimensions=latent_dims,\n",
    "    base_experiment_name=\"GeoLinearAE_LatentDim\",\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Results from latent dimension exploration:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f56f1af",
   "metadata": {},
   "source": [
    "## 5. Comparing Different Autoencoder Architectures\n",
    "\n",
    "The `MultiArchitectureManager` class helps compare different autoencoder architectures on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MultiArchitectureManager\n",
    "multi_arch_manager = MultiArchitectureManager(\n",
    "    results_dir='results/geo_architecture_comparison'\n",
    ")\n",
    "\n",
    "# Add different architectures to compare\n",
    "multi_arch_manager.add_architecture(\n",
    "    name=\"SimpleLinear\",\n",
    "    model_class=SimpleLinearAutoencoder\n",
    ")\n",
    "\n",
    "multi_arch_manager.add_architecture(\n",
    "    name=\"DeeperLinear\",\n",
    "    model_class=DeeperLinearAutoencoder\n",
    ")\n",
    "\n",
    "multi_arch_manager.add_architecture(\n",
    "    name=\"Convolutional\",\n",
    "    model_class=ConvAutoencoder\n",
    ")\n",
    "\n",
    "multi_arch_manager.add_architecture(\n",
    "    name=\"Variational\",\n",
    "    model_class=VariationalAutoencoder\n",
    ")\n",
    "\n",
    "# Set up the common dataset\n",
    "multi_arch_manager.setup_common_dataset(consistent_layers_dataset)\n",
    "\n",
    "# Run the comparison\n",
    "comparison_results = multi_arch_manager.run_comparison(\n",
    "    latent_dims=[10],  # Using 10 dimensions for all models\n",
    "    epochs=15,         # Train each model for 15 epochs\n",
    "    batch_size=32,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Generate and save a summary report\n",
    "multi_arch_manager.save_summary_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5b550",
   "metadata": {},
   "source": [
    "## 6. Loading Pre-trained Models\n",
    "\n",
    "You can save and load trained models for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained linear autoencoder model\n",
    "saved_model_path = linear_ae_wrapper.save_model()\n",
    "print(f\"Model saved to: {saved_model_path}\")\n",
    "\n",
    "# Create a new wrapper and load the saved model\n",
    "new_wrapper = AutoEncoderWrapper(\n",
    "    model_class=SimpleLinearAutoencoder,\n",
    "    model_name=\"LoadedGeoLinearAE\",\n",
    "    device=device,\n",
    "    results_dir='results/loaded_geo_models'\n",
    ")\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = new_wrapper.load_model(saved_model_path)\n",
    "\n",
    "# Test the loaded model\n",
    "new_wrapper.test_loader = test_loader\n",
    "test_loss, test_metrics = new_wrapper.evaluate(\n",
    "    visualize=True,\n",
    "    num_samples=5\n",
    ")\n",
    "\n",
    "print(f\"Test loss with loaded model: {test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15d191",
   "metadata": {},
   "source": [
    "## 7. Comparing Consistent vs. Variable Layers\n",
    "\n",
    "Let's compare how autoencoders perform on the consistent vs. variable geological layer datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for the variable layers dataset\n",
    "variable_train_loader = DataLoader(variable_train, batch_size=batch_size, shuffle=True)\n",
    "variable_val_loader = DataLoader(variable_val, batch_size=batch_size, shuffle=False)\n",
    "variable_test_loader = DataLoader(variable_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Train a convolutional autoencoder on consistent layers\n",
    "consistent_conv_ae = AutoEncoderWrapper(\n",
    "    model_class=ConvAutoencoder,\n",
    "    model_name=\"ConsistentLayersConvAE\",\n",
    "    input_shape=input_shape,\n",
    "    latent_dim=10,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    results_dir='results/consistent_layers_conv_ae'\n",
    ")\n",
    "\n",
    "# Setup data\n",
    "consistent_conv_ae.train_loader = train_loader\n",
    "consistent_conv_ae.val_loader = val_loader\n",
    "consistent_conv_ae.test_loader = test_loader\n",
    "consistent_conv_ae.dataloader_setup = True\n",
    "\n",
    "# Train the model (fewer epochs for demonstration)\n",
    "consistent_model, consistent_metrics = consistent_conv_ae.train(\n",
    "    epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    early_stopping_patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Train a convolutional autoencoder on variable layers\n",
    "variable_conv_ae = AutoEncoderWrapper(\n",
    "    model_class=ConvAutoencoder,\n",
    "    model_name=\"VariableLayersConvAE\",\n",
    "    input_shape=input_shape,\n",
    "    latent_dim=10,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    results_dir='results/variable_layers_conv_ae'\n",
    ")\n",
    "\n",
    "# Setup data\n",
    "variable_conv_ae.train_loader = variable_train_loader\n",
    "variable_conv_ae.val_loader = variable_val_loader\n",
    "variable_conv_ae.test_loader = variable_test_loader\n",
    "variable_conv_ae.dataloader_setup = True\n",
    "\n",
    "# Train the model (fewer epochs for demonstration)\n",
    "variable_model, variable_metrics = variable_conv_ae.train(\n",
    "    epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    early_stopping_patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Compare reconstructions\n",
    "from autoencoder_lib.visualization.reconstructions import compare_reconstructions\n",
    "\n",
    "# Create a mixed test loader with both types\n",
    "import torch\n",
    "mixed_test_data = []\n",
    "mixed_test_labels = []\n",
    "\n",
    "for i in range(5):\n",
    "    # Add consistent sample\n",
    "    data, _ = consistent_test[i]\n",
    "    mixed_test_data.append(data)\n",
    "    mixed_test_labels.append(torch.tensor(0))  # Label 0 for consistent\n",
    "    \n",
    "    # Add variable sample\n",
    "    data, _ = variable_test[i]\n",
    "    mixed_test_data.append(data)\n",
    "    mixed_test_labels.append(torch.tensor(1))  # Label 1 for variable\n",
    "\n",
    "mixed_test_data = torch.stack(mixed_test_data)\n",
    "mixed_test_labels = torch.stack(mixed_test_labels)\n",
    "\n",
    "# Compare the reconstructions of both models\n",
    "fig = compare_reconstructions(\n",
    "    [consistent_model, variable_model],\n",
    "    [\"Consistent Layers Model\", \"Variable Layers Model\"],\n",
    "    DataLoader(torch.utils.data.TensorDataset(mixed_test_data, mixed_test_labels), batch_size=10),\n",
    "    device,\n",
    "    num_samples=10,\n",
    "    title=\"Comparing Models Trained on Different Geological Patterns\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750c1e5",
   "metadata": {},
   "source": [
    "## 8. Finding Minimum Latent Dimension for Geological Data\n",
    "\n",
    "Use the `find_minimum_latent_dim` method to determine the minimum number of latent dimensions needed to achieve acceptable reconstruction quality for geological patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634004d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new experiment manager for the geologic dataset\n",
    "geo_exp_manager = ExperimentManager(\n",
    "    model_class=ConvAutoencoder,  # Using convolutional AE for the geologic data\n",
    "    results_dir='results/geologic_min_latent_dim'\n",
    ")\n",
    "\n",
    "# Find minimum latent dimension for consistent layers\n",
    "min_dim_consistent, results_df_consistent = geo_exp_manager.find_minimum_latent_dim(\n",
    "    dataset=consistent_layers_dataset,\n",
    "    dimensions_to_try=[2, 4, 8, 16, 32],\n",
    "    base_experiment_name=\"ConsistentGeoConvAE\",\n",
    "    epochs=10,\n",
    "    threshold=0.1,  # Allow 10% relative loss increase\n",
    "    batch_size=32,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Minimum latent dimension for consistent layers: {min_dim_consistent}\")\n",
    "print(\"Results for consistent layers:\")\n",
    "print(results_df_consistent)\n",
    "\n",
    "# Find minimum latent dimension for variable layers\n",
    "min_dim_variable, results_df_variable = geo_exp_manager.find_minimum_latent_dim(\n",
    "    dataset=variable_layers_dataset,\n",
    "    dimensions_to_try=[2, 4, 8, 16, 32],\n",
    "    base_experiment_name=\"VariableGeoConvAE\",\n",
    "    epochs=10,\n",
    "    threshold=0.1,  # Allow 10% relative loss increase\n",
    "    batch_size=32,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Minimum latent dimension for variable layers: {min_dim_variable}\")\n",
    "print(\"Results for variable layers:\")\n",
    "print(results_df_variable)\n",
    "\n",
    "# Compare the results\n",
    "import matplotlib.pyplot as plt\n",
    "from autoencoder_lib.visualization.training import plot_metric_vs_latent_dim\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(results_df_consistent['latent_dim'], results_df_consistent['test_loss'], 'o-', label='Consistent Layers')\n",
    "ax.plot(results_df_variable['latent_dim'], results_df_variable['test_loss'], 's-', label='Variable Layers')\n",
    "ax.set_xlabel('Latent Dimension')\n",
    "ax.set_ylabel('Test Loss')\n",
    "ax.set_title('Reconstruction Loss vs Latent Dimension by Dataset Type')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8537f",
   "metadata": {},
   "source": [
    "## 9. Advanced: Using a Variational Autoencoder with Geological Data\n",
    "\n",
    "Let's train a Variational Autoencoder (VAE) on the geological data to enable smoother latent space representation and generative capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wrapper for a Variational Autoencoder\n",
    "geo_vae_wrapper = AutoEncoderWrapper(\n",
    "    model_class=VariationalAutoencoder,\n",
    "    model_name=\"GeologyVAE\",\n",
    "    input_shape=input_shape,\n",
    "    latent_dim=10,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    results_dir='results/geo_vae'\n",
    ")\n",
    "\n",
    "# Setup data\n",
    "geo_vae_wrapper.train_loader = train_loader\n",
    "geo_vae_wrapper.val_loader = val_loader\n",
    "geo_vae_wrapper.test_loader = test_loader\n",
    "geo_vae_wrapper.dataloader_setup = True\n",
    "\n",
    "# Train the VAE model\n",
    "model, metrics = geo_vae_wrapper.train(\n",
    "    epochs=20,\n",
    "    learning_rate=0.001,\n",
    "    early_stopping_patience=5,\n",
    "    verbose=True,\n",
    "    visualize_training=True\n",
    ")\n",
    "\n",
    "# Evaluate and visualize\n",
    "test_loss, test_metrics = geo_vae_wrapper.evaluate(visualize=True, num_samples=10)\n",
    "geo_vae_wrapper.visualize_latent_space(method='tsne', class_names=['Consistent Layers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317b5da",
   "metadata": {},
   "source": [
    "## 10. Latent Space Traversal with Geological VAE\n",
    "\n",
    "With a trained Variational Autoencoder, we can traverse the latent space to generate new geological layer patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the latent traversal visualization function\n",
    "from autoencoder_lib.visualization.latent_space import plot_latent_traversal\n",
    "\n",
    "# Generate latent space traversals\n",
    "fig = plot_latent_traversal(\n",
    "    model=geo_vae_wrapper.model,\n",
    "    latent_dim=5,  # Visualize the first 5 dimensions\n",
    "    steps=8,       # 8 steps from -2 to 2 in each dimension\n",
    "    device=device,\n",
    "    figsize=(15, 10)\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Create some synthetic geological patterns by sampling the latent space\n",
    "plt.figure(figsize=(12, 8))\n",
    "with torch.no_grad():\n",
    "    # Sample random points in latent space\n",
    "    z = torch.randn(16, geo_vae_wrapper.latent_dim).to(device)\n",
    "    \n",
    "    # Generate images\n",
    "    generated = geo_vae_wrapper.model.decode(z).cpu()\n",
    "    \n",
    "    # Plot\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(generated[i].squeeze(), cmap='gray')\n",
    "        plt.title(f\"Sample {i+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Synthetic Geological Patterns Generated by VAE\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45492e7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the `autoencoder_lib` package with geological layer datasets to:\n",
    "\n",
    "1. Load and visualize geological layer data\n",
    "2. Train different autoencoder architectures on geological patterns\n",
    "3. Compare performance between consistent and variable layer datasets\n",
    "4. Find the minimum latent dimensions needed for geological patterns\n",
    "5. Generate synthetic geological patterns using variational autoencoders\n",
    "6. Visualize latent space representations of geological features\n",
    "7. Compare different architectures for geological pattern analysis\n",
    "\n",
    "This geological application demonstrates how autoencoders can be used to analyze and generate complex spatial patterns, with potential applications in geology, remote sensing, and earth science."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
