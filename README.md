# AutoEncoder Experimentation Framework

A comprehensive Python package for systematic exploration of autoencoder latent space discrimination capabilities across different datasets and architectures.

## ğŸ¯ Project Overview

This project investigates how autoencoder neural networks represent different types of images and geometric features in latent space. The primary research goals are to:

- Understand latent space discrimination capabilities
- Determine when latent space breaks down for specific features
- Identify minimum latent features needed for effective discrimination
- Analyze how incrementally complex features are encoded

## ğŸš€ Current Status

**Phase 0: Migration from Jupyter Notebook to Python Package**

- âœ… TaskMaster-AI project management initialized
- âœ… Git repository setup with comprehensive .gitignore
- ğŸ”„ Migrating from `AutoEncoderJupyterTest.ipynb` to modular Python package
- ğŸ”„ Creating four core wrapper functions for clean notebook interface

## ğŸ“ Project Structure

```
AutoEncoder_Experimentation/
â”œâ”€â”€ autoencoder_lib/          # Target Python package (to be created)
â”‚   â”œâ”€â”€ data/                 # Dataset generation and loading utilities
â”‚   â”œâ”€â”€ models/               # Autoencoder architecture definitions
â”‚   â”œâ”€â”€ experiment/           # Training and experiment management
â”‚   â”œâ”€â”€ visualization/        # Visualization functions and utilities
â”‚   â””â”€â”€ utils/                # Helper functions and utilities
â”œâ”€â”€ scripts/                  # Project documentation and configuration
â”‚   â”œâ”€â”€ prd.txt              # Product Requirements Document
â”‚   â””â”€â”€ task-complexity-report.json
â”œâ”€â”€ tasks/                    # TaskMaster-AI task management
â”œâ”€â”€ AutoEncoderJupyterTest.ipynb    # Original implementation (reference)
â””â”€â”€ README.md                 # This file
```

## ğŸ”¬ Research Datasets

### Geological Datasets
- **Consistent Layers**: Layered geological patterns with consistent properties
- **Variable Layers**: Layered patterns with variable characteristics
- Designed to test discrimination of subtle geological features

### Progressive Complexity
- Starting with similar classes containing extremely subtle differences
- Gradually adding more complex features to probe latent space thresholds
- Framework designed to handle any generic dataset

## ğŸ—ï¸ Target Architecture

### Four Core Wrapper Functions
1. **Dataset Generation Wrapper**: Generate any generic dataset with visualization
2. **Dataset Visualization Wrapper**: t-SNE projection and dataset analysis
3. **Experiment Runner Wrapper**: Systematic exploration of autoencoder models
4. **Results Loader Wrapper**: Load and visualize results from saved experiments

### Autoencoder Architectures
- Standard symmetric autoencoders
- Variational autoencoders (VAEs)
- Convolutional autoencoders
- Adversarial autoencoders
- Sparse autoencoders

## ğŸ› ï¸ Development Setup

### Prerequisites
- Python 3.8+
- PyTorch
- NumPy, Matplotlib, Scikit-learn
- Jupyter Notebook

### Installation (Coming Soon)
```bash
# Clone the repository
git clone https://github.com/yourusername/AutoEncoder_Experimentation.git
cd AutoEncoder_Experimentation

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸ“Š Current Workflow (Jupyter Notebook)

The existing workflow consists of 5 sequential code blocks:

1. **Dataset Generation**: Generates datasets with visualization and class examples
2. **Dataset Visualization**: t-SNE projection visualization of specified dataset
3. **Model Definitions**: Defines autoencoder architectures and model classes
4. **Experiment Execution**: Systematic exploration with specified parameters
5. **Results Loading**: Retrieves and visualizes results from saved experiments

## ğŸ¯ Migration Goals

### Critical Requirements
- âœ… Preserve 100% of current functionality
- ğŸ”„ Fix visualization consistency issues between run and load operations
- ğŸ”„ Support any generic dataset and autoencoder architecture
- ğŸ”„ Implement high-level parameter configuration
- ğŸ”„ Create clean, maintainable Python package structure

### Key Improvements
- **Reproducibility**: Consistent visualizations with explicit seed management
- **Generalization**: Abstract interfaces for datasets and architectures
- **Maintainability**: Modular code structure for future development
- **Usability**: Simple, intuitive interface for complex experiments

## ğŸ“ˆ Task Management

This project uses [TaskMaster-AI](https://github.com/taskmaster-ai/taskmaster-ai) for systematic task management:

- **15 main tasks** organized by priority and dependencies
- **AI-powered complexity analysis** for task breakdown
- **Research-backed task generation** using Perplexity AI
- **Comprehensive progress tracking** and dependency management

View current tasks: `task-master list`
Get next task: `task-master next`

## ğŸ¤ Contributing

This project follows a strict Git workflow:

1. **Feature Branches**: All development on feature branches
2. **Descriptive Commits**: Clear, actionable commit messages
3. **Pull Requests**: All merges via pull request review
4. **No Direct Main Commits**: Main branch protected

### Branch Naming Convention
- `feature/migrate-data-module`
- `feature/migrate-models-module`
- `bugfix/visualization-consistency`
- `docs/update-documentation`

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ”— Related Work

- Original Jupyter notebook implementation: `AutoEncoderJupyterTest.ipynb`
- Backup implementation: `AutoEncoderJupyterTest_BACKUP.ipynb`
- Project documentation: `scripts/prd.txt`

## ğŸ“ Contact

For questions about this research project, please open an issue or contact the development team.

---

**Status**: ğŸš§ Active Development - Migration Phase 0
**Last Updated**: 2025-05-27 