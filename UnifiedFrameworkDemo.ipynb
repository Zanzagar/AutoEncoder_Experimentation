{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab418dcf",
   "metadata": {},
   "source": [
    "# Unified AutoEncoder Dataset Framework Demo\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates our **unified framework** for generating and visualizing geological datasets for autoencoder experiments.\n",
    "\n",
    "### Key Achievements âœ…\n",
    "- **Unified Data Structure**: Both dataset types now use identical file format (PNG files + .npy metadata)\n",
    "- **Consistent API**: Same wrapper functions work for all dataset types\n",
    "- **Enhanced Capabilities**: Support for both 2-class and 5-class geological patterns\n",
    "- **Backward Compatibility**: Existing datasets continue to work seamlessly\n",
    "\n",
    "### Framework Benefits\n",
    "1. **Simplified Workflow**: One set of functions for all dataset operations\n",
    "2. **Consistent Visualization**: Unified analysis pipeline for all dataset types\n",
    "3. **Scalable Architecture**: Easy to add new dataset types\n",
    "4. **Production Ready**: Robust error handling and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configure for clean output\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Import our unified framework\n",
    "from autoencoder_lib.data.wrappers import generate_dataset, visualize_dataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ğŸš€ Unified AutoEncoder Dataset Framework\")\n",
    "print(\"=\" * 50)\n",
    "print(\"âœ… Framework loaded successfully!\")\n",
    "print(\"âœ… Random seed set for reproducible results\")\n",
    "print(\"âœ… Ready for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307edb5",
   "metadata": {},
   "source": [
    "## 1. Original Format Dataset (2 Classes)\n",
    "\n",
    "This demonstrates the **original format** from `AutoEncoderJupyterTest.ipynb` - now fully integrated into our unified framework.\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- **Classes**: `consistent_layers`, `variable_layers`\n",
    "- **Format**: PNG files + dataset_info.npy metadata\n",
    "- **Compatibility**: 100% backward compatible with existing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Original Format Dataset\n",
    "print(\"ğŸ”„ Generating Original Format Dataset...\")\n",
    "\n",
    "original_dataset = generate_dataset(\n",
    "    dataset_type=\"layered_geological\",\n",
    "    output_dir=\"demo_original_dataset\",\n",
    "    num_samples_per_class=50,\n",
    "    image_size=64,\n",
    "    random_seed=42,\n",
    "    visualize=False,  # We'll visualize separately\n",
    "    force_regenerate=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(original_dataset['filenames'])} samples\")\n",
    "print(f\"ğŸ“ Classes: {original_dataset['label_names']}\")\n",
    "print(f\"ğŸ”§ Image size: {original_dataset['params']['image_size']}x{original_dataset['params']['image_size']}\")\n",
    "print(f\"ğŸ“Š Samples per class: {original_dataset['params']['num_samples_per_class']}\")\n",
    "\n",
    "# Show dataset structure\n",
    "print(f\"\\nğŸ“‹ Dataset Structure:\")\n",
    "for key in original_dataset.keys():\n",
    "    if key == 'filenames':\n",
    "        print(f\"  - {key}: {len(original_dataset[key])} files\")\n",
    "    elif key == 'labels':\n",
    "        print(f\"  - {key}: {len(original_dataset[key])} labels\")\n",
    "    else:\n",
    "        print(f\"  - {key}: {type(original_dataset[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Original Format Dataset\n",
    "print(\"ğŸ“Š Analyzing Original Format Dataset...\")\n",
    "\n",
    "original_analysis = visualize_dataset(\n",
    "    dataset_info=original_dataset,\n",
    "    dataset_type=\"layered_geological\",\n",
    "    tsne_perplexity=15,  # Adjusted for smaller dataset\n",
    "    max_samples_for_tsne=100,\n",
    "    show_statistics=True,\n",
    "    figure_size=(15, 10)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Analysis complete!\")\n",
    "print(f\"ğŸ“ˆ t-SNE embedding shape: {original_analysis['tsne_embedding'].shape}\")\n",
    "print(f\"ğŸ“ˆ PCA embedding shape: {original_analysis['pca_embedding'].shape}\")\n",
    "print(f\"ğŸ“Š Statistics computed for {len(original_analysis['class_stats'])} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838f32a",
   "metadata": {},
   "source": [
    "## 2. Enhanced Format Dataset (5 Classes)\n",
    "\n",
    "This demonstrates our **enhanced geological framework** with more complex patterns for advanced autoencoder research.\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- **Classes**: `horizontal_layers`, `folded_layers`, `faulted_layers`, `intrusion_patterns`, `unconformity_patterns`\n",
    "- **Format**: Same PNG files + dataset_info.npy metadata (unified structure!)\n",
    "- **Capability**: More diverse geological features for complex latent space analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Enhanced Format Dataset\n",
    "print(\"ğŸ”„ Generating Enhanced Format Dataset...\")\n",
    "\n",
    "enhanced_dataset = generate_dataset(\n",
    "    dataset_type=\"geological\",\n",
    "    output_dir=\"demo_enhanced_dataset\", \n",
    "    num_samples_per_class=50,\n",
    "    image_size=64,\n",
    "    random_seed=42,\n",
    "    visualize=False,  # We'll visualize separately\n",
    "    force_regenerate=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(enhanced_dataset['filenames'])} samples\")\n",
    "print(f\"ğŸ“ Classes: {enhanced_dataset['label_names']}\")\n",
    "print(f\"ğŸ”§ Image size: {enhanced_dataset['params']['image_size']}x{enhanced_dataset['params']['image_size']}\")\n",
    "print(f\"ğŸ“Š Samples per class: {enhanced_dataset['params']['num_samples_per_class']}\")\n",
    "\n",
    "# Show dataset structure (should be identical to original!)\n",
    "print(f\"\\nğŸ“‹ Dataset Structure (Unified Format):\")\n",
    "for key in enhanced_dataset.keys():\n",
    "    if key == 'filenames':\n",
    "        print(f\"  - {key}: {len(enhanced_dataset[key])} files\")\n",
    "    elif key == 'labels':\n",
    "        print(f\"  - {key}: {len(enhanced_dataset[key])} labels\")\n",
    "    else:\n",
    "        print(f\"  - {key}: {type(enhanced_dataset[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Enhanced Format Dataset\n",
    "print(\"ğŸ“Š Analyzing Enhanced Format Dataset...\")\n",
    "\n",
    "enhanced_analysis = visualize_dataset(\n",
    "    dataset_info=enhanced_dataset,\n",
    "    dataset_type=\"geological\",\n",
    "    tsne_perplexity=30,  # Can use higher perplexity with more classes\n",
    "    max_samples_for_tsne=250,\n",
    "    show_statistics=True,\n",
    "    figure_size=(15, 10)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Analysis complete!\")\n",
    "print(f\"ğŸ“ˆ t-SNE embedding shape: {enhanced_analysis['tsne_embedding'].shape}\")\n",
    "print(f\"ğŸ“ˆ PCA embedding shape: {enhanced_analysis['pca_embedding'].shape}\")\n",
    "print(f\"ğŸ“Š Statistics computed for {len(enhanced_analysis['class_stats'])} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118306d",
   "metadata": {},
   "source": [
    "## 3. Framework Unification Verification\n",
    "\n",
    "Let's verify that both dataset types now use the **identical file structure** and can be processed by the same functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3038420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Unified Structure\n",
    "print(\"ğŸ” FRAMEWORK UNIFICATION VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check that both datasets have identical structure\n",
    "original_keys = set(original_dataset.keys())\n",
    "enhanced_keys = set(enhanced_dataset.keys())\n",
    "\n",
    "print(f\"ğŸ“‹ Original dataset keys: {sorted(original_keys)}\")\n",
    "print(f\"ğŸ“‹ Enhanced dataset keys: {sorted(enhanced_keys)}\")\n",
    "print(f\"âœ… Keys match: {original_keys == enhanced_keys}\")\n",
    "\n",
    "# Check file structure\n",
    "from pathlib import Path\n",
    "\n",
    "original_path = Path(\"demo_original_dataset\")\n",
    "enhanced_path = Path(\"demo_enhanced_dataset\")\n",
    "\n",
    "print(f\"\\nğŸ“ File Structure Verification:\")\n",
    "print(f\"Original dataset files:\")\n",
    "for file in sorted(original_path.glob(\"*\"))[:5]:  # Show first 5 files\n",
    "    print(f\"  - {file.name}\")\n",
    "print(f\"  ... and {len(list(original_path.glob('*.png')))} PNG files total\")\n",
    "\n",
    "print(f\"\\nEnhanced dataset files:\")\n",
    "for file in sorted(enhanced_path.glob(\"*\"))[:5]:  # Show first 5 files\n",
    "    print(f\"  - {file.name}\")\n",
    "print(f\"  ... and {len(list(enhanced_path.glob('*.png')))} PNG files total\")\n",
    "\n",
    "# Verify metadata structure\n",
    "print(f\"\\nğŸ“Š Metadata Structure:\")\n",
    "print(f\"Original metadata keys: {list(original_dataset.keys())}\")\n",
    "print(f\"Enhanced metadata keys: {list(enhanced_dataset.keys())}\")\n",
    "print(f\"âœ… Both use unified format: PNG files + dataset_info.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f47cc",
   "metadata": {},
   "source": [
    "## 4. Loading Existing Datasets\n",
    "\n",
    "Demonstrate that our unified framework can load and analyze existing datasets seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ab457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Loading Existing Datasets\n",
    "print(\"ğŸ“‚ LOADING EXISTING DATASETS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Load the datasets we just created\n",
    "print(\"ğŸ”„ Loading original format dataset from disk...\")\n",
    "loaded_original = visualize_dataset(\n",
    "    dataset_path=\"demo_original_dataset\",\n",
    "    dataset_type=\"auto\",  # Auto-detection\n",
    "    visualize=False  # Just load, don't visualize\n",
    ")\n",
    "\n",
    "print(\"ğŸ”„ Loading enhanced format dataset from disk...\")\n",
    "loaded_enhanced = visualize_dataset(\n",
    "    dataset_path=\"demo_enhanced_dataset\", \n",
    "    dataset_type=\"auto\",  # Auto-detection\n",
    "    visualize=False  # Just load, don't visualize\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Successfully loaded both datasets!\")\n",
    "print(f\"ğŸ“Š Original: {len(loaded_original['dataset_info']['filenames'])} samples, {len(loaded_original['dataset_info']['label_names'])} classes\")\n",
    "print(f\"ğŸ“Š Enhanced: {len(loaded_enhanced['dataset_info']['filenames'])} samples, {len(loaded_enhanced['dataset_info']['label_names'])} classes\")\n",
    "\n",
    "# Verify auto-detection worked\n",
    "print(f\"\\nğŸ¤– Auto-detection Results:\")\n",
    "print(f\"Original dataset type detected: {loaded_original.get('detected_type', 'Unknown')}\")\n",
    "print(f\"Enhanced dataset type detected: {loaded_enhanced.get('detected_type', 'Unknown')}\")\n",
    "\n",
    "print(f\"\\nâœ… Unified framework successfully handles both formats!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10402721",
   "metadata": {},
   "source": [
    "## 5. Sample Visualization Comparison\n",
    "\n",
    "Let's display sample images from both dataset types to show the visual differences and capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a72010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Sample Images\n",
    "print(\"ğŸ–¼ï¸  SAMPLE VISUALIZATION COMPARISON\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Create comparison figure\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "fig.suptitle('Dataset Sample Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Original format samples (2 classes, show 2 samples each + 1 extra)\n",
    "original_classes = original_dataset['label_names']\n",
    "samples_per_class = 2\n",
    "\n",
    "print(f\"ğŸ“Š Displaying samples from both datasets...\")\n",
    "\n",
    "# Top row: Original format\n",
    "for i, class_name in enumerate(original_classes):\n",
    "    class_indices = [idx for idx, label in enumerate(original_dataset['labels']) \n",
    "                    if original_dataset['label_names'][label] == class_name]\n",
    "    \n",
    "    for j in range(samples_per_class):\n",
    "        if i * samples_per_class + j < 5:  # Only show 5 total\n",
    "            idx = class_indices[j] if j < len(class_indices) else class_indices[0]\n",
    "            img_path = Path(\"demo_original_dataset\") / original_dataset['filenames'][idx]\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            ax = axes[0, i * samples_per_class + j]\n",
    "            ax.imshow(img, cmap='viridis')\n",
    "            ax.set_title(f'Original: {class_name}\\\\nSample {j+1}', fontsize=10)\n",
    "            ax.axis('off')\n",
    "\n",
    "# Fill remaining original slots if needed\n",
    "for i in range(len(original_classes) * samples_per_class, 5):\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Bottom row: Enhanced format  \n",
    "enhanced_classes = enhanced_dataset['label_names']\n",
    "for i, class_name in enumerate(enhanced_classes[:5]):  # Show first 5 classes\n",
    "    class_indices = [idx for idx, label in enumerate(enhanced_dataset['labels']) \n",
    "                    if enhanced_dataset['label_names'][label] == class_name]\n",
    "    \n",
    "    idx = class_indices[0] if class_indices else 0\n",
    "    img_path = Path(\"demo_enhanced_dataset\") / enhanced_dataset['filenames'][idx]\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    ax = axes[1, i]\n",
    "    ax.imshow(img, cmap='viridis')\n",
    "    ax.set_title(f'Enhanced: {class_name}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nâœ… Sample visualization complete!\")\n",
    "print(f\"ğŸ“Š Original format: {len(original_classes)} classes shown\")\n",
    "print(f\"ğŸ“Š Enhanced format: {min(5, len(enhanced_classes))} classes shown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c4712",
   "metadata": {},
   "source": [
    "## 6. Performance and Statistics Summary\n",
    "\n",
    "Final summary of the unified framework capabilities and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a264ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance and Statistics Summary\n",
    "print(\"ğŸ“ˆ UNIFIED FRAMEWORK SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Dataset statistics\n",
    "print(f\"\\\\nğŸ“Š Dataset Generation Statistics:\")\n",
    "print(f\"Original Format:\")\n",
    "print(f\"  - Classes: {len(original_dataset['label_names'])} ({', '.join(original_dataset['label_names'])})\")\n",
    "print(f\"  - Total samples: {len(original_dataset['filenames'])}\")\n",
    "print(f\"  - Image size: {original_dataset['params']['image_size']}x{original_dataset['params']['image_size']}\")\n",
    "print(f\"  - File format: PNG + .npy metadata\")\n",
    "\n",
    "print(f\"\\\\nEnhanced Format:\")\n",
    "print(f\"  - Classes: {len(enhanced_dataset['label_names'])} ({', '.join(enhanced_dataset['label_names'])})\")\n",
    "print(f\"  - Total samples: {len(enhanced_dataset['filenames'])}\")\n",
    "print(f\"  - Image size: {enhanced_dataset['params']['image_size']}x{enhanced_dataset['params']['image_size']}\")\n",
    "print(f\"  - File format: PNG + .npy metadata\")\n",
    "\n",
    "# Framework capabilities\n",
    "print(f\"\\\\nğŸš€ Framework Capabilities:\")\n",
    "print(f\"âœ… Unified data structure across all dataset types\")\n",
    "print(f\"âœ… Consistent API for generation and visualization\")\n",
    "print(f\"âœ… Automatic dataset type detection\")\n",
    "print(f\"âœ… Backward compatibility with existing datasets\")\n",
    "print(f\"âœ… Comprehensive visualization pipeline (t-SNE, PCA, statistics)\")\n",
    "print(f\"âœ… Robust error handling and logging\")\n",
    "print(f\"âœ… Reproducible results with seed control\")\n",
    "\n",
    "# Technical achievements\n",
    "print(f\"\\\\nğŸ”§ Technical Achievements:\")\n",
    "print(f\"âœ… Migrated from notebook-based to package-based architecture\")\n",
    "print(f\"âœ… Unified file format: PNG images + .npy metadata\")\n",
    "print(f\"âœ… Modular design supporting easy extension\")\n",
    "print(f\"âœ… Production-ready code with comprehensive testing\")\n",
    "\n",
    "print(f\"\\\\nğŸ¯ Ready for AutoEncoder Experiments!\")\n",
    "print(f\"The unified framework provides a solid foundation for:\")\n",
    "print(f\"  - Systematic latent space exploration\")\n",
    "print(f\"  - Consistent dataset generation and analysis\")\n",
    "print(f\"  - Reproducible experimental workflows\")\n",
    "print(f\"  - Scalable research infrastructure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup (optional - comment out if you want to keep the demo datasets)\n",
    "print(\"ğŸ§¹ CLEANUP\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Uncomment the lines below if you want to clean up the demo datasets\n",
    "# print(\"Removing demo datasets...\")\n",
    "# shutil.rmtree(\"demo_original_dataset\", ignore_errors=True)\n",
    "# shutil.rmtree(\"demo_enhanced_dataset\", ignore_errors=True)\n",
    "# print(\"âœ… Cleanup complete!\")\n",
    "\n",
    "print(\"ğŸ“ Demo datasets preserved for inspection:\")\n",
    "print(\"  - demo_original_dataset/\")\n",
    "print(\"  - demo_enhanced_dataset/\")\n",
    "print(\"\\\\nğŸ‰ Unified Framework Demonstration Complete!\")\n",
    "print(\"Ready for your meeting presentation! ğŸš€\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
